# ðŸ”¥ News
- *2025.06*: ðŸŽ‰ [DataTailor](https://github.com/Yuqifan1117/DataTailor) are accepted by ICCV2025! Codes are available!
- *2025.05*: ðŸŽ‰ Two papers are accepted by ICML 2025! OmniBench developed a multi-dimensional visual agent benchmark, and Similar proposed a Step-wise Multi-dimensional Generalist Reward Model.
- *2025.04*: ðŸŽ‰ AnyEdit is accepted by CVPR2025 as Oral presentation! We are delighted to release [AnyEdit](https://dcd-anyedit.github.io/) with code & dataset, which is a comprehensive multi-modal instruction editing dataset.
- *2025.02*: ðŸŽ‰ Two papers are accepted by CVPR 2025! [AnyEdit](https://dcd-anyedit.github.io/) received full scores (5,5,5) from the community
- *2024.09*: ðŸŽ‰ 1 Paper is accepted by NeurIPS 2024.
- *2024.02*: ðŸŽ‰ HalluciDoctor is accepted by CVPR 2024! [HalluciDoctor](https://github.com/Yuqifan1117/HalluciDoctor) is the first to investigate the severe hallucination toxicity in existing MLLM datasets.
- *2023.08*: ðŸ”¥ We released [Baby-DALL3](https://github.com/Yuqifan1117/Labal-Anything-Pipeline), which can annotate anything in visual tasks and generate anything just all in one pipeline with GPT-4.
- *2023.06*: I received my first paper, [CaCao](https://github.com/Yuqifan1117/CaCao), in ICCV 2023. Welcome to STAR and FORK!
