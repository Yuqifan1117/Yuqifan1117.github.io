{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "uodH3cwAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Qifan Yu", "affiliation": "Zhejiang University", "organization": 1118375729466322660, "interests": ["MLLM", "multimodal learning", "image generation & editing"], "email_domain": "@zju.edu.cn", "homepage": "https://github.com/Yuqifan1117", "citedby": 225, "publications": {"uodH3cwAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Hallucidoctor: Mitigating hallucinatory toxicity in visual instruction data", "pub_year": "2024"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:u-x6o8ySG0sC", "num_citations": 93, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4916463011442892259", "cites_id": ["4916463011442892259"]}, "uodH3cwAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visually-prompted language model for fine-grained scene graph generation in an open world", "pub_year": "2023"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:9yKSN-GCB0IC", "num_citations": 44, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13927866830150625993", "cites_id": ["13927866830150625993"]}, "uodH3cwAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Anyedit: Mastering unified high-quality image editing for any idea", "pub_year": "2025"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:IjCSPb-OGe4C", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5993128768996714865", "cites_id": ["5993128768996714865"]}, "uodH3cwAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Interactive data synthesis for systematic vision adaptation via llms-aigcs collaboration", "pub_year": "2023"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:u5HHmVD_uO8C", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3359205223589499612", "cites_id": ["3359205223589499612"]}, "uodH3cwAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dancing avatar: Pose and text-guided human motion videos synthesis with image diffusion model", "pub_year": "2023"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:d1gkVwhDpl0C", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6779897968662855225", "cites_id": ["6779897968662855225"]}, "uodH3cwAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards unified multimodal editing with enhanced knowledge collaboration", "pub_year": "2024"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:2osOgNQ5qMEC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8367299329339889643", "cites_id": ["8367299329339889643"]}, "uodH3cwAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "STEP: Enhancing Video-LLMs' Compositional Reasoning by Spatio-Temporal Graph-guided Self-Training", "pub_year": "2025"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:zYLM7Y9cAGgC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11676667504578343632", "cites_id": ["11676667504578343632"]}, "uodH3cwAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unified Generative and Discriminative Training for Multi-modal Large Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:UeHWp8X0CEIC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15558786185812970610", "cites_id": ["15558786185812970610"]}, "uodH3cwAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mastering Collaborative Multi-modal Data Selection: A Focus on Informativeness, Uniqueness, and Representativeness", "pub_year": "2024"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:Tyk-4Ss8FVUC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16165094871082512235", "cites_id": ["16165094871082512235"]}, "uodH3cwAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DEMON24: ACM MM24 Demonstrative Instruction Following Challenge", "pub_year": "2024"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:qjMakFHDy7sC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14783434245696573884", "cites_id": ["14783434245696573884"]}, "uodH3cwAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Boosting Virtual Agent Learning and Reasoning: A Step-wise, Multi-dimensional, and Generalist Reward Model with Benchmark", "pub_year": "2025"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:W7OEmFMy1HYC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8833138263023128792", "cites_id": ["8833138263023128792"]}, "uodH3cwAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities", "pub_year": "2025"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:YsMSGLbcyi4C", "num_citations": 0}, "uodH3cwAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SOYO: A Tuning-Free Approach for Video Style Morphing via Style-Adaptive Interpolation in Diffusion Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "uodH3cwAAAAJ:Y0pCki6q_DkC", "num_citations": 0}}, "citedby5y": 225, "hindex": 6, "hindex5y": 6, "i10index": 5, "i10index5y": 5, "cites_per_year": {"2023": 16, "2024": 82, "2025": 127}, "updated": "2025-06-30 10:17:39.825140"}